---
title: "At-site flood frequency analysis using peaks over threshold"
output: 
    rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{peaks-over-threshold}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}

---

## Introduction

This document presents how `CSHShydRology` can be used to perform at-site flood
frequency analysis using threshold modeling. 
This example is illustrated using the daily discharges of the Saint-John River 
at Fort Kent (NB).
The dataset `flowStJohn` has two columns: `date` and `flow`.
The column `flow` contains numerical values reporting daily 
river discharges and the column `date` is of class `Date`. 

First a verification is done to make sure that only complete years of data are 
included.
In this case, all years are complete except 1926. 
See the code below.

```{r}
library(CSHShydRology)
data(flowStJohn)

## Extract the year
y <- format(flowStJohn$date,'%Y')

## Evaluate the record length of each year 
ty <- tapply(y, y, length)

## Print the years with missing values
print(ty[which(ty < 365)])

## Identify observations associated with a complete year
cid <- y %in% names(ty[ty>=365])

## Keep only complet year
xd <- cbind(flowStJohn[cid,], year = y[cid])
```

In some occasions the middle of the time series may present missing values that
can be assumed to be regular streamflow values (not extreme). 
In this situation, one could pad the missing values with value sufficiently low
so that they will not be treated as peaks.

## Estimating model parameters

The Function `FitPot` estimates the parameter of a Generalized Pareto
distribution (GPA) assuming that the data are independent exceedances.
$$ 
F(x)= \exp\left\{- \left( 1-\kappa \frac{x}{\alpha} \right)^{1/\kappa} \right\}
$$
The recommended estimation method is the maximum likelihood (MLE), 
but the L-moment and moment-based method can be employed by passing the argument 
`method = 'lmom'` or `'mom'`.
For MLE, confidence intervals of the parameters are derived using the delta 
method, while parametric bootstrap is needed for the other methods.


```{r}
## Random sample of GPA
rx <- rgpa(2000, 1, 0)

## Fitting POT using MLE
fit <- FitPot(rx, unit = 1)
print(fit)
```


In some occasions symmetrical confidence intervals can be unrealistic.  
In this case, one should prefer the confidence intervals provided 
by the profile likelihood method as returned by the function `coef`.

```{r}
## Show assymetrical confidence intervals
round(coef(fit, ci = TRUE),3)
```

At this stage, the Anderson-Darling test can be used to verify if the observed
peaks were likely to have been generated by a GPA distribution.
By default, this probability  that the sample was generated 
by the GPA distribution (p-value) is interpotaled using the table provided by
Choulaki and Stephen (2001), which is bound to a 0.5 for practical reason.
Higher p-values show more evidence of a proper model.
Alternatively, parametric bootstraps can be used to evaluate the p-values using 
the argument `method = 'ad'` and the number of necessary simulations.
As expected, the example below shows high p-values that confirms that the data
was indeed simulated from a GPA distribution.

```{r}
## AD test using MLE and a table
GofTest(fit)

## AD test using the method of moment and bootstrap. 
fitm <- FitPot(rx, method = 'mom', varcov = FALSE) 
GofTest(fitm, method = 'ad', nsim = 500)
```


## Selecting the threshold

An important aspect of threshold modeling is the selection of the threshold. 
This decision is normally based on the notion of stability, which entails 
that if $u$ is a well-chosen threshold then all the exceedances for all
thresholds $u^\ast \geq u$ follow a GPA with the same shape parameter.
The objective is therefore to find the lowest threshold that ensures such 
stability. 
One visual assessment of the threshold stability is provided by the mean 
residual life plot (MRL).
In this graph, the mean of the exceedances is plotted against a list of
candidate thresholds.
When stability is reached, the MRL plot should exhibit a linear trend.
In the figure below, the MRL plot indicates that thresholds greater than 
1000 are reasonable choices.
Note that a declustering method is used to extract independent peaks, which 
will be discussed later.

```{r, fig.height = 4, fig.width = 6}
## List of candidate thresholds
ulst <- seq(500,1500, 25)

## Mean residual life plot
r0 <- 14
PlotMrl(flow~date, xd, u = ulst, declust = 'wrc', r = r0)
```

However, due to sampling error, MRL plots do not always lead to a clear cut
decision.
Another approach for selecting a threshold is by looking 
directly at the evolution of the shape parameter with respect to the thresholds.
The function `SearchThresh` returns key statistics of the POT model for several 
candidate thresholds.
The graphics below show that above `u = 1000` the shape parameter is stable and
leads to coherent estimated flood quantiles.
Vertical lines are references that shows the nearest candidate thresholds 
associated with 1 and 1.5 peaks per years .


```{r, fig.height = 4, fig.width = 6}
candidates <- SearchThresh(flow~date, xd, u = ulst, declust = 'wrc', r = r0,
                           verbose = FALSE)

PlotThresh(candidates,  type = c('kappa'))
```

```{r, fig.height = 4, fig.width = 6}
PlotThresh(candidates,  type = c('q2','q5','q10','q20','q50'))
```

The process of selecting a good threshold can be automatized using a goodness of
fit test like the AD test (Davison and Smith, 1990).
The function `SearchThresh` also extracts the p-value of that test for every 
candidate threshold. 
The figure below shows that below a threshold of approximately 900, the 
p-values of the AD test are low and do not support the hypothesis of a GPA. 
After this changing point, the p-values increase until reaching 0.5 for a 
threshold of about 950. 

```{r, fig.height = 4, fig.width = 6}
PlotThresh(candidates,  type = c('ad'))
```

For the common significance levels like 0.05, it was found that such procedure 
often selects too low of a threshold and so, Solari et al. (2017) suggested 
to use instead the maximum p-value. 
Alternatively, Durocher et al. (2018) suggested using a critical values 
between 0.10 and 0.25 to avoid higher probability of falsely acceptating the 
GPA (False positive).
According to this latter criteria, the lowest stable threshold among 
the candidates is found at `u = 925`, while the maximum is `u = 950`.
These values can be extracted using the function `FindThresh` with argument
`method = 'max'` or `method = 'sgn'`.
The argument `ppy` can be used to remove candidate
thresholds that have excess rate outsite a desired interval.

```{r}
## Threshold with maximum AD p-value
cvars <- c('u','ppy','ad','q50')
FindThresh(candidates, method = 'max')[,cvars]

## First threshold with AD p-value > 0.25
FindThresh(candidates, method = 'sgn', tol.sgn = 0.25, 
           ppy = c(1,3))[,cvars]

```

Another method to automatically select the threshold is to impose a given 
excess rate. 
By passing the argument `type = 'ppy'` and `tol.ppy = 2.2`, the candidate 
threshold with the excess rate the closest to 2.2 is returned.

```{r}
## Threshold with approximately 2.2 PPY
FindThresh(candidates, method = 'ppy', tol.ppy = 2.2)[,cvars]
```

In some situations a critical p-value such as 0.25 may not be reached or the 
threshold associated with a given excess rate may lead to samples that aren't 
well approximated by a GPA.
Mixing criteria for automatically selecting a threshold may lead to 
a more robust procedure (Durocher et al., 2018). 
The approach `sgn` has the advantage of generally leading to
more precise estimations as it includes more peaks and ensures that GPA is a
reasonable model.  
The arguments `sgn-max` or `sgn-ppy` ask the function `FindThresh` to search 
for the `sgn` threshold and if it cannot be found, will return the alternative 
candidates.


```{r}

## Create a situation where there is no treshold associated with a p-value
## greater than 0.25
candidates.mod <- candidates
candidates.mod$ad <- pmin(0.2, candidates.mod$ad)

## First threshold with AD p-value > 0.25
FindThresh(candidates.mod, method = 'sgn-ppy', 
           tol.sgn = 0.25, tol.ppy = 2.2)[,cvars]

FindThresh(candidates.mod, method = 'sgn-ppy', 
           tol.sgn = 0.15, tol.ppy = 2.2)[,cvars]
```


With the approach `sgn`, the function `FindThresh` can also reject
thresholds where the relative discrepency between the flood quantile of the 
selected threshold and a reference threshold is too large.
This serves as an additional verification that flood quantiles tend to remain
stable after the selected threshold.
The reference threshold is defined as the average of the flood quantiles 
associated with the 5 lowest thresholds among the candidates.
In the example below, the argument `ppy = c(1,3)` is used to impose a lower 
bound of 1 PPY which leads to a reference of about 1 PPY.
With the St-John River, the flood quantiles quickly stabilize.
After a threshold of `u = 825`, the relative discrepencies between the selected
and reference threshold is less than 1%.
This behavior is produced by a distribution with a light tail.


```{r}
## Verify the discrepencies with reference threshold ~ 1PPY
FindThresh(candidates, method = 'sgn', ppy = c(1,3), tol.sgn = 0.0, 
           qua = 'q50', tol.qua = .01)[,cvars]

FindThresh(candidates, method = 'sgn', ppy = c(1,3), tol.sgn = 0.25, 
           qua = 'q50', tol.qua = .01)[,cvars]

```

## Declustering

In practice, daily streamflow evolves smoothly and declustering techniques are 
necessary to extract independent flood peaks above a given threshold $u$. 
Without declustering, exceedances are likely to be found in clusters.
Two functions are available to extract independent peaks: `which.cluster` and 
`which.floodPeaks`. 
The first method is a running declustering method that extracts the maximum of 
each cluster separated by at least `r` observations below the threshold. 
Such methods may be more appropriate for extracting rainfall events. 
The second method follows the recommendation of the Water Resource Council of 
the United States as described in Lang et al. (1999). 
In brief, two adjacent peaks must respect the following two conditions: 
(i) they must be separated by $4+log(A)$ days, where $A$ is the drainage area 
in square kilometers; and (ii) the minimal intermediate flow must be less than 
75% of the lowest of the two peaks.
The example below illustrates the extraction of the peaks by the two methods. 
It is seen that the choice of a declustering method has an impact
on the extracted peaks.

```{r fig.height = 4,fig.width = 6}

## Define a threshold and the minimum separating time. Drainage Area =  14700.
thresh <- 500
r0 <- round(4 + log(14700)) # ~14 days

## Extract peaks based on run declustering
peaks1 <- which.clusters(flow~date, xd, u = thresh, r = 5)

## Extract peaks based on WRC recommendations
peaks2 <- which.floodPeaks(flow~date, xd, u = thresh, r = r0, rlow = 0.75)

## Plot the peaks extracted for the year 1927
plot(flow~date, xd[xd$year == 1927,],type = 'l', col = 'grey')
abline(h = thresh, col = 2 ,lwd = 2)
points(flow~date, xd[peaks1,], pch = 16, col = 'blue', cex=2)
points(flow~date, xd[peaks2,], pch = 17, col = 'red')
legend('topleft', col = c('blue','red'), pch = 16:17, 
       legend = c('Cluster','WRC'))

```

The declustering techniques are integrated into the function `FitPot` and 
are performed when the argument `declust` is passed. 
The example below leads to the identification of the same peaks as in `peaks2` 
above, before fitting a GPA distribution.  

```{r}
## Fit a POT model after declustering
fit <- FitPot(flow~date, xd, u = 1000, declust = 'wrc', r = r0)
print(fit)
```

## Predicting flood quantiles

For the present data, the estimated shape parameter is positive, which 
indicates that the distribution has an upper bound $u + \alpha/\kappa$.
The flood quantiles $x_T$ of a $T$ year return period event is defined as the 
quantile of probability $[1-1/(\lambda T)]$ of the exceedance distribution, 
where $\lambda$ is the excess rate (average number of exceedances per 
year or PPY).
For the GPA distribution the flood quantiles are given by
$$
x_T = u + \frac{\alpha}{\kappa}\left[ 1 - \left(\lambda T\right)^{-\kappa}
\right],
$$
and a natural estimator of $\lambda$ is the number of flood events over the number
of years of observations.

The flood quantiles are evaluated by the function `predict`, where
the standard deviation and confidence intervals are included by passing 
the argument `ci`.
In the example below, the profile likelihood method is used to evaluate the 
confidence intervals of the flood quantiles of 10 and 100 year return periods.
Other available methods are the delta method (`delta`) and 
parametric bootstraps (`boot`).
An overview of the estimated flood quantile is provided by the return level plot
that express the flood quantile (return level) versus the return periods.


```{r fig.height=5, fig.width=6}
## Predict flood quantile of return period 10 and 100 years
predict(fit, rt = c(10,100), se = TRUE, ci = 'profile')

## Return level plot
plot(fit, ci = TRUE)
```

## Nonstationary POT models

There are different types of trends that can affect the outcomes of a flood frequency analysis when using peaks over threshold. 
One possibility is a change in the number of events per years. 
One strategy suggested to deal with this phenomenon is to consider a time-varying threshold determined by quantile regression (Kyselý et al. 2010). 
Contrary to standard regression, the output of quantile regression is a parametric function, that cut the distribution at a specific probability $\tau$. 
For example, $\tau = 0.5$ implies that a time-vayring median is evaluated.
Please remark that due to use of a declustering technique to identify 
independent peaks among the daily flows,
the probability $tau$ is not an estimator of exceedance rate of the peaks, 
although they should be connected.  
Having $x(t)$ the observation at time $t$ and $u(t)$, a simple linear model 
for the threshold is 
$$
 u(t) = a_1 \, t + a_0
$$
The example below transforms the previous daily river discharge above the daily 
average to create data that will require a nonstationary threshold. 
The nonstationary POT model with time-dependent threshold can be fitted using the function `FitNsPot`.
The latter works similar to `FitPot`, but require a formula to specify the
time-dependent threshold and the argument `tau` the probability of the quantile function.

```{r}
## Create trend in the data
idm <- xd$flow > mean(xd$flow)
xd$utrend <- xd$flow 
xd$utrend[idm] <- xd$utrend[idm] + as.integer(xd$date[idm]) * 0.02
  
## Fit the model
fit <- FitNsPot(utrend~ date, x = xd, tau = .95, declust = 'wrc', r = 14,
                thresh = ~ date)
plot(fit)

```

At this stage, A Poisson or logistic regression model can be used to verify if the threshold have corrected the trend in the number of peaks.
The code below looks at a possible trend in the number of peaks per year using poison regression. 
In the result table, the p-value associated with the slope of the time-varying treshold is superior to 0.05, which suggests that the trend is significant.

```{r}
## Count the number of peaks per years
xn <- data.frame(date = fit$data[fit$peak,2])
xn$year <- as.integer(format(xn$date, '%Y'))
xn <- aggregate(date~year, xn, length)

## Fitting a Poisson regression model
ff <- glm(date~year, xn, family = quasipoisson())
print(summary(ff)$coef, digit = 3)
```

In the previous graphics, we can see that the mean excess is parallel to the threshold as it was assumed constant.
Even if the exceedance rate is constant, it is possible that the mean excess 
is also time-dependent. 
Considering $m(t)$ the mean excess, a nonstationary model 
that considers both a time-varying threshold and mean excess may assume that at 
each time $t$ the distribution of the standardized values

$$
z(t) = \frac{x(t) - u(t)}{m(t)}
$$
is constant and follows a GPA with mean equal to 1. 
Noting that the mean and variance of a GPA are 
$$
\begin{align}
\mu &= \frac{\alpha}{1+\kappa} \\
\sigma^2 & = \frac{\mu^2}{1+2\kappa}  
\end{align}
$$
these assumptions imply that $z(t)$ follows a $GPA(1+\kappa, \kappa)$. 
The trend in the mean excess can be estimated by maximum likelihood or by regression.
For the regression approach, the quasi-likelihood method is used in this situation because it treats $\kappa$ as a nuisance parameter and take into account that the square relation between the mean and the variance (Durocher et al., 2019).
After the fitting of the model is done, the $\kappa$ parameter can be estimated from the standardized values using moment-based estimators.
By default a combination of regression and L-moments method is invoked by using `method = 'reg-lmom'` or by `'reg-mom'` to use classical moments.
For the maximum likelihood estimates the method must be set to `'mle'`.
The example below employed constant, linear model and 
a second order polynomial model to describe the evolution of the mean excess. 
An AIC can be evaluated based ont the standardized values.
It should be pointed out that this criterion cannot be used to select or verify the validity of the time-varying threshold as it assumes the threshold to be known.
The results below suggest that the linear trend is the best model according to 
its AIC.
Other tests for detecting trends, like the test of Mann-Kendall, could also be employed to look at the significance of the trend in the mean excess. 

```{r}
## Fit the model
fit0 <- FitNsPot(flow~ date, x = xd, tau = .95, declust = 'wrc', r = 14,
                trend = ~ 1)

fit <- FitNsPot(flow ~ date, x = xd, tau = .95, declust = 'wrc', r = 14,
                trend = ~ date)

fit3 <- FitNsPot(flow~ date, x = xd, tau = .95, declust = 'wrc', r = 14,
                trend = ~ poly(date,2))

c(AIC(fit0), AIC(fit), AIC(fit3))
plot(fit)

```

In the nonstationary framework, the probability of exceedance of an event dependent of the time $t$ and so, the notion of return period in terms of an expected waiting time must be generalized.
Although such generalizations exist, it is not a practical approach as
it requires the extrapolation of the trends over a long period of time.
For example, to estimate a 100-year event we need to evaluate a trend over more 
than 100 years, which is impossible to do accurately.
Nevertheless, it is still common in practice to call $x_p(t)$ a $T$-year event.

Another way to look at flood risks is in terms of a number of exceeding events. 
Reliability is defined as the probability that no event exceeds a given design level during a finite period of time.
The opposite is the risk of failure, which corresponds to the probability that at least one such event occurs.
Let's denote $p_i(x_R)$ the probability of not exceeding $x_R$ at year $t_i$,
the reliability of the design level $x_R$ over a period $t_1, \ldots, t_s$ is 
$$
R = \prod_{i=1}^s p_i(x_R).
$$
Note that is assumes that $Z(t_i)$ is independent of $Z(t_j)$ for $i\neq j$.
This can be solved numerically to identify a design flood of a given level $R$.
It should be noted that in the stationary framework, the reliability of an event 
of probability $p$ over $s$ years is $R = p^s$.
For instance, for $T = 20$ and $N = 30$ we have a reliability of $0.95^{30} \approx 0.215$, which at the opposite implies that we have a risk of failure of $0.785$. 
For the rest of the document, we will use this relationship to define a design
level of return period $T$ as an event with reliability $p^s$.
Accordingly $p$ is the geometric mean of the $p_i(x_R)$ and therefore
the design level of return period $T$ is a central measure for the flood quantiles
$x_p(t)$ during the same return period.

The example below illustrates how the function `fitted` is used to extract 
the components of the nonstationary model at a specific date.
In the following, we will use the values of July 15th as an approximation of the yearly flood risk and we will focus on the last 30 years.
The flood quantiles and the design level are evaluated with the function 
`predict` for different return period.


```{r}
yr <- which.day(flowStJohn$date, '0715')
yr <- yr[59:88]

## Extract the threshold and trend
xf <- fitted(fit, newdata = flowStJohn[yr,])
head(xf)

## Graph of the 
plot(fit, do.legend = FALSE)

qua <- predict(fit, rt = c(10,50), newdata = flowStJohn)
rel <- predict(fit, rt = c(10,50), newdata = flowStJohn[yr,],
               reliability = TRUE)

lines(flowStJohn$date, qua[,1], col = 'magenta', lwd = 2, lty = 2)
arrows(min(xf$time), rel[1], max(xf$time), col = 'cyan', lwd = 3,
       code = 3, length = .1 )

legend('topleft', legend = c('Flood quantile','Design level'), 
       col = c('magenta','cyan'), lty = c(2,1))
```

Inference about the nonstationary model can be carried out by parametric bootstraps.
The function `BootNsPot` is used to simplify that process as shown in the 
example below.

```{r}
hat <- BootNsPot(fit, x = flowStJohn, newdata = flowStJohn[yr,], nsim = 50, 
                 reliability = TRUE, verbose = FALSE)
summary(hat, variable = 'para')
summary(hat, variable = 'qua')
```

To guide the search of a threshold in the nonstationary framework, a similar
approach based on the p-value of the Anderson-Darling test can be used as
previously presented.
The new strategy requires the application of the test on the standardized
values $z(t)$, whose by construction must GPA.
This goodness-of-fit can be evaluated using the `GofTest` function. 
More generally the function `SearchThreshNs` can be used to automatize the
process in the same ways as `SearchThresh`.
In particular, the same function can be used to extract the information and 
help to select the threshold (e.g. `Findthresh`).


```{r}
tau <- seq(.93, .98, .002)
candidates.tau <- SearchThreshNs(flow~date, flowStJohn, tau = tau, 
                       trend = ~ poly(date,3), thresh = ~ date, method = 'mle',
                       declust = 'wrc', r = 14, newdata = flowStJohn[yr,])

## First threshold with AD p-value > 0.25
FindThresh(candidates.tau, method = 'sgn-max', ppy = c(1,3))[,cvars]

```

```{r, fig.height = 8, fig.width = 8}
layout(matrix(c(1,3,2,4),2,2))
plot(ad~u, candidates.tau, type = 'l')
plot(mrl~u, candidates.tau, type = 'l')
plot(kappa~u, candidates.tau, type = 'l')
plot(q50~u, candidates.tau, type = 'l')
```

## Conclusion

In this document, it was shown how threshold modeling can be carried out  
to estimate flood quantiles for different return periods.
Instructions for fitting the model (`FitPot`), evaluate the uncertainty of 
the parameters (`coef`) and derive the flood quantiles were provided 
(`predict`).
Basic validation procedures based on the mean residual life plot
(`PlotMrl`) and goodness of fit tests (`GofTest`) were shown to assess the 
fitting of the model.  
Finally, automatic procedures to select a best candidate threshold were 
discussed (`SearchThresh` and `FindThresh`).

For a general introduction to the technical aspects of threshold modeling, 
the reader is referred to Coles (2001) or Davison and Smith (1990).

## References

Choulakian, V., Stephens, M.A. (2001). Goodness-of-Fit Tests for the Generalized Pareto Distribution. Technometrics 43, 478–484. https://doi.org/10.2307/1270819

Coles, S., 2001. An introduction to statistical modeling of extreme values. Springer Verlag.

Davison, A.C., Smith, R.L. (1990). Models for Exceedances over High Thresholds. Journal of the Royal Statistical Society. Series B (Methodological) 52, 393–442.

Durocher, M., Zadeh, S.M., Burn, D.H., Ashkar, F. (2018). Comparison of automatic procedures for selecting flood peaks over threshold based on goodness-of-fit tests. Hydrological Processes 0. https://doi.org/10.1002/hyp.13223

Durocher, M., Burn, D. H., & Ashkar, F. (2019). Comparison of estimation methods for a nonstationary index-flood model in flood frequency analysis using peaks over threshold [Preprint]. https://doi.org/10.31223/osf.io/rnepc

Kyselý, J., Picek, J., & Beranová, R. (2010). Estimating extremes in climate change simulations using the peaks-over-threshold method with a non-stationary threshold. Global and Planetary Change, 72(1), 55–68. https://doi.org/10.1016/j.gloplacha.2010.03.006


Lang, M., Ouarda, T.B.M.J., Bobée, B. (1999). Towards operational guidelines for over-threshold modeling. Journal of Hydrology 225, 103–117. https://doi.org/10.1016/S0022-1694(99)00167-5

Solari, S., Egüen, M., Polo, M.J., Losada, M.A. (2017). Peaks Over Threshold (POT): A methodology for automatic threshold estimation using goodness of fit p-value. Water Resour. Res. 53, 2833–2849. https://doi.org/10.1002/2016WR019426

